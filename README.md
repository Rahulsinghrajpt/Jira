00) Hi Sair. Sir, actually I implemented a logic for schema drift detection, so that if the source (0:09) files that are coming from Tracer, if they have different schema from what is expected, (0:17) so it will give us an alert. And while doing that, there are some bugs in the data ingestion pipeline (0:24) which I tried to fix, but I think I need a little more time to fix that.
So I humbly request you (0:32) to kindly allow me one day time so that I can fix the entire pipeline and make it ready for testing. (0:44) Please provide me just one day exception and tomorrow I will be ready with the data ingestion (0:50) pipeline, so that we can perform the end-to-end testing.



Investigating and fixing data integrity issues in the data ingestion pipeline. Two bugs: (1) Missing columns in destination files — Sales (from {retailer}_sales), In_stock_Rate, and Promo_flag are dropped for some retailers; retailer-specific columns (Amazon_impressions, Bestbuy_spend, etc.) are missing for multi-retailer files like National. (2) Pipeline info table not updating — last_data_updated isn't being set because ConditionExpression fails for legacy records without created_at. Root cause: column selection logic isn't matching retailer-specific columns due to case-sensitivity and missing variations. Applied fixes: added capitalized retailer identifiers for case-insensitive matching, added diagnostic logging, and fixed pipeline info update to check record existence first. Next: deploy and test with all retailer files, verify columns are present, monitor CloudWatch logs. No blockers. ETA: resolution by end of day.
